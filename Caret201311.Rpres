<style type="text/css"> 
.reveal section code{ 
  font-size: 95%; 
} 
.reveal section code.r{ 
  font-size: 100%; 
} 
.reveal .state-background {background: lightgrey;}
</style>


The Caret Package
========================================================
author: Syrus Nemat-Nasser (R [at] syrus [dot] us)
date: November 19, 2013
width: 1200
height: 700
autosize: false

&nbsp;

https://github.com/Syrus/201311

```{r include=FALSE}
library(knitr)
opts_chunk$set(fig.path='figure/caret-', dev='png', fig.width=10, fig.height=5, dpi=180)
opts_chunk$set(cache=TRUE)
options(width=100)
```

The Caret Package for R
========================================================

*Classification And REgression Training*

&nbsp;

Caret was created by Max Kuhn
- http://cran.r-project.org/web/packages/caret/
- http://caret.r-forge.r-project.org/
- http://appliedpredictivemodeling.com/

&nbsp;
```{r eval=FALSE}
install.packages("caret", dependencies=c("Depends", "Suggests"))
```

Aside: Load Useful Packages
========================================================
```{r}
library(ggplot2)
library(plyr)
library(caret)
```

Note that Caret will automatically load packages as needed. We only need to load Caret to start using it.

Regression
========================================================

<center>
**Ideal Problem**

${\bf y} = {\bf r}({\bf x}) + \bf{\epsilon}$

${\bf x} \in \mathbb{R}^n$

${\bf y} \in \mathbb{R}^m$
</center>
*****
<center>
**Model**

${\bf h}({\bf x}) \in \mathbb{R}^m$

${\bf h}({\bf x}) \simeq {\bf r}({\bf x})$

&nbsp;

**Objective Function**

$\min(||{\bf h}({\bf x}) - {\bf r}({\bf x})||^l)$

</center>

Caret Features
========================================================

- Pre-Processing

- Data Splitting

- Model Training and Tuning

- Visualizations

- Variable Importance

- Feature Selection

- Parallel Processing

Caret Features
========================================================
transition: fade
transition-speed: slow

- **Pre-Processing**

- Data Splitting

- **Model Training and Tuning**

- Visualizations

- Variable Importance

- Feature Selection

- **Parallel Processing**


Example Data | UCI HAR Data
========================================================

<small>http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones</small>

Experimental data were collected from 30 human subjects.

Subjects carried a smartphone to record accelerometer and rate gyro sensor data.

Time-frequency features were computed from the raw sensor data.*

The goal was to determine the *human activity* from the measured data. 

After running the knitr::spin notebook [**uciHarAnalysis.R**](https://github.com/Syrus/201311/blob/master/uciHarAnalysis.R):
```{r}
load("UCI HAR Dataset/dataset.RData")
```

<center><small><font color="darkslategray">* Raw sensor data are also included in the download.</font></small></center>

UCI HAR Data Set | Training and Hold-out
========================================================
```{r echo=FALSE}
train$Partition="Train"
test$Partition = "Test"
uciHar = rbind(train,test) # combine sets for visualization
uciHar$Partition = as.factor(uciHar$Partition)
numPredictors = ncol(uciHar) - 3
```
```{r echo=FALSE}
qplot(data=uciHar, x=subject, fill=Partition)
```

UCI HAR Data Set | Target Variable
========================================================
```{r echo=FALSE}
qplot(data=uciHar, x=subject, fill=Activity)
```


UCI HAR Data Set | Predictor Variables
========================================================
```{r}
s = sample(1:numPredictors, 18) # select 18 randomly-selected predictors
str(uciHar[,s])
```
<center><font color="darkgreen">There are `r numPredictors`
predictor variables.</font></center>

UCI HAR Data Set | Predictor Variable "Normalization"
========================================================
```{r echo=FALSE}
trainSd = colwise(sd)(train[,1:numPredictors])
trainSd$stat = "Predictor Variable Standard Deviation"
trainMean = colwise(mean)(train[,1:numPredictors])
trainMean$stat = "Predictor Variable Mean"
temp = melt(rbind(trainMean, trainSd), c("stat"))
qplot(data=temp, x=value, binwidth = 0.025) + facet_wrap(~ stat, ncol=1)
rm(temp,trainMean,trainSd)
```


Caret Pre-Processing
========================================================

Caret Function       | Description
---------------------|-------------------
**dummyVars**        | Generate dummy variables from factors
**nearZeroVar**      | Identify variables with low variance
**findCorrelation**  | Identify highly correlated variables
**findLinearCombos** | Enumerate sets of linear combinations
**preProcess**       | Centering and scaling; PCA; ICA; missing value imputation
**classDist**        | Generate predictor variables from the distance to class centroids


Aside: Discrete predictor variables
========================================================
```{r}
library(earth)
data(etitanic)
etitanic$survived = as.logical(etitanic$survived)
str(etitanic)
summary(etitanic)
```

Aside: Discrete predictor variables
========================================================

**caret::dummyVars**

```{r}
dummies <- dummyVars(survived ~ ., data = etitanic)
head(predict(dummies, newdata = etitanic))
str(predict(dummies, newdata = etitanic))
```
```{r include=FALSE}
rm(etitanic, dummies)
```

Pre-Processing Continuous Variables
========================================================

**caret::preProcess**

```{r include=FALSE}
load("workspaceImage.RData")
```

```{r eval=FALSE}
zScaleTrain = preProcess(train[,1:numPredictors], method=c("center", "scale")) 
scaledX = predict(zScaleTrain, train[,1:numPredictors])
```
```{r}
range(colwise(mean)(scaledX))
range(colwise(sd)(scaledX))
```

```{r eval=FALSE}
pcaTrain = preProcess(scaledX, method="pca", thresh=0.99)
pcaX = predict(pcaTrain, scaledX)
```
<center><small>The PCA transformed data retains `r pcaTrain$numComp` components to capture `r 100*pcaTrain$thresh`% of the variance.</small></center>

<center><small>Methods for preProcess include "BoxCox", "YeoJohnson", "expoTrans", "center", "scale", "range", "knnImpute", "bagImpute", "pca", "ica" and "spatialSign".</small></center>

Aside: Principal Component Analysis (1)
=========================================================
```{r}
pcaResults = prcomp(scaledX, tol=sqrt(.Machine$double.eps))
plot(pcaResults)
```

Aside: Principal Component Analysis (2)
=========================================================
```{r}
temp=data.frame(index=1:length(pcaResults$sdev), Variance=(pcaResults$sdev)**2)
q = qplot(data=temp, index, Variance)
print(q)
```

Aside: Principal Component Analysis (3)
=========================================================
```{r}
print(q + scale_y_log10())
```

Pre-Processing Continuous Variables
=========================================================

**caret::findCorrelation**

```{r eval=FALSE}
correlatedPredictors = findCorrelation(cor(scaledX), cutoff=0.95)
reducedCorrelationX = scaledX[,-correlatedPredictors]
```
<center><small>We removed `r length(correlatedPredictors)` correlated predictors leaving us with `r numPredictors - length(correlatedPredictors)` predictors.</small></center>
```{r}
head(names(scaledX))
head(names(reducedCorrelationX))
head(names(pcaX))
```

Caret Data Splitting
=========================================================

Caret Functions         |
------------------------|
**createDataPartition** |
**maxDissim**           |
**minDiss**             |
**sumDiss**             |

<font color="darkgreen">*The UCI HAR data set has a pre-selected hold-out sample.*</font>

UCI HAR Data Set | Cross-validation
=========================================================

The HAR training data comes from a small number of human subjects
```{r}
summary(train$subject)
```

&nbsp;

Prepare for cross-validation
```{r eval=FALSE}
cvBreaks = 7
temp = sample(levels(train$subject), length(levels(train$subject))) # randomize subjects
temp = split(temp, cut(1:length(temp), breaks=cvBreaks, labels=FALSE)) # split into CV groups
cvGroupIndices = lapply(temp, function(X) {which(!train$subject %in% X)})
```

Caret Model Training and Tuning
=======================================================

Training Functions      |
------------------------|
**train**               |
**trainControl**        |

Evaluation Functions    |
------------------------|
**predict.train**       |
**confusionMatrix**     |

&nbsp;

<center>http://caret.r-forge.r-project.org/modelList.html</center>

Model Training and Tuning | method='knn'
=======================================================

```{r eval=FALSE}
knnCtrl = trainControl(method="cv", number=length(cvGroupIndices)
                       , index=cvGroupIndices, classProbs=TRUE)
modelKnn = train(reducedCorrelationX, train$Activity, method="knn", trControl=knnCtrl
                 , tuneGrid = data.frame(.k = c(5,10,15,20)))
print(modelKnn)
```

```{r echo=FALSE}
print(modelKnn)
```

Model Training and Tuning | method='knn'
=======================================================

```{r echo=TRUE}
confusionMatrix(modelKnn)
modelKnn$times
```

Model Training and Tuning | method='knn'
=======================================================

```{r echo=TRUE}
plot(modelKnn)
```


Model Training and Tuning | method='rf'
=======================================================

```{r eval=FALSE}
rfCtrl = trainControl(method="cv", number=length(cvGroupIndices)
                      , index=cvGroupIndices, classProbs=TRUE)
modelRF = train(reducedCorrelationX, train$Activity, method="rf", trControl=rfCtrl
                , tuneGrid = data.frame(.mtry = c(2,5,10,15,20)), importance=TRUE)
print(modelRF)
```

```{r echo=FALSE}
print(modelRF)
```

Model Training and Tuning | method='rf'
=======================================================

```{r echo=TRUE}
confusionMatrix(modelRF)
modelRF$times
```

Model Training and Tuning | method='rf'
=======================================================

```{r echo=TRUE}
plot(modelRF)
```

Model Training and Tuning | method='parRF'
=======================================================

```{r eval=FALSE}
parRfCtrl = trainControl(method="cv", number=length(cvGroupIndices)
                         , index=cvGroupIndices, classProbs=TRUE)
modelParRF = train(reducedCorrelationX, train$Activity, method="parRF", trControl=parRfCtrl
                   , tuneGrid = data.frame(.mtry = c(2,5,10,15,20)), importance=TRUE)
print(modelParRF)
```

```{r echo=FALSE}
print(modelParRF)
```

Model Training and Tuning | method='parRF'
=======================================================

```{r echo=TRUE}
confusionMatrix(modelParRF)
modelParRF$times
```

Model Training and Tuning | method='parRF'
=======================================================

```{r echo=TRUE}
plot(modelParRF)
```


Parallel Processing
=======================================================

Recent versions of R include the **parallel** package.

I was able to get Caret to use multiple cores with the CRAN package **doParallel**.

```{r eval=FALSE}
require(parallel)
cl = parallel::makeForkCluster(nnodes=detectCores()/2)
setDefaultCluster(cl)
require(doParallel)
registerDoParallel(cl)
```

When Caret detects a registered parallel backend, it automatically parallelizes the model training and tuing process.

UCI HAR Data Set | Choosing a Model
======================================================

&nbsp;

For simplicity, I choose the *best* model based on cross-validation accuracy.

```{r echo=FALSE}
temp = rbind(
    data.frame(method="knn", max.accuracy=max(modelKnn$results$Accuracy)
               , accuracySD=(modelKnn$results$AccuracySD[which(modelKnn$results$Accuracy == max(modelKnn$results$Accuracy))]))
    , data.frame(method="rf", max.accuracy=max(modelRF$results$Accuracy)
               , accuracySD=(modelRF$results$AccuracySD[which(modelRF$results$Accuracy == max(modelRF$results$Accuracy))]))
    , data.frame(method="parRF", max.accuracy=max(modelParRF$results$Accuracy)
               , accuracySD=(modelParRF$results$AccuracySD[which(modelParRF$results$Accuracy == max(modelParRF$results$Accuracy))]))
    )
temp$method = as.factor(temp$method)
temp
```

&nbsp;

- The two random forest models have equivalent performance.

- CV predicts an accuracy of 93% with a standard deviation of 4%.

UCI HAR Data Set | Final Model (1)
=========================================================
```{r eval=FALSE}
bestModel = modelRF # choose the best model

## Apply data preprocessing steps to hold-out set
holdoutX = predict(zScaleTrain, test[,1: numPredictors])[,-correlatedPredictors]
holdoutLabels = test$Activity

## Use the model to predict outcomes for the hold-out set
holdoutPrediction = predict(bestModel, holdoutX) # default type="raw"
head(holdoutPrediction)
```
```{r echo=FALSE}
head(holdoutPrediction)
```

```{r echo=TRUE}
classProbPrediction = predict(bestModel, holdoutX, type="prob")
head(classProbPrediction)
```

UCI HAR Data Set | Final Model (2a)
=========================================================
```{r}
cvCM = confusionMatrix(bestModel) # cross-validation predictions
print(100 * (cvCM$table / sum(cvCM$table)), digits=1)
holdoutCM = confusionMatrix(holdoutPrediction, holdoutLabels)
print(100 * (holdoutCM$table / sum(holdoutCM$table)), digits=1)
```

Aside: Renormalize confustion matrix
=========================================================
```{r}
renormalizeConfusionMatrixColumns = function(cm) {
    cm / rep(colSums(cm), times=nrow(cm), ncol=ncol(cm), byrow=TRUE)
    }

renormalizeConfusionMatrixColumns(cvCM$table)
```

<center>*Each column sums to 1.*</center>

UCI HAR Data Set | Final Model (2b)
=========================================================
```{r}
## Cross validation confusion matrix
print(100 * renormalizeConfusionMatrixColumns(cvCM$table), digits=1)
## Hold-out confusion matrix
print(100 * renormalizeConfusionMatrixColumns(holdoutCM$table), digits=1)
```

UCI HAR Data Set | Final Model (3)
=========================================================

```{r}
## Compute the overall accuracy of bestModel for the hold-out data
holdoutAccuracy = sum(diag(holdoutCM$table)) / sum(holdoutCM$table)
holdoutAccuracy
```

<center>The overall accuracy for the hold-out data set was about `r formatC(100*holdoutAccuracy, digits=2)`%.</center>


**Model Deployment**

```{r eval=FALSE}
## Save model
save(zScaleTrain, correlatedPredictors, bestModel, file="bestModel.RData")

## Use model
require(caret)
load("bestModel.RData")
scaledReducedX = predict(zScaleTrain, newDataX)[,-correlatedPredictors]
newDataPrediction = predict(bestModel, scaledReducedX)
```

Aside: Random Forest OOB
=========================================================

RF uses out-of-bag (OOB) analysis to estimate test set error.

```{r}
tail(modelRF$finalModel$err.rate)
```
```{r include=FALSE}
## check that model confusion matrix confirms oob err.rate
temp = modelRF$finalModel$confusion
oob.accuracy = sum(diag(temp)) / sum(temp)
oob.accuracy
```
OOB was unaware of **train$subject**.

OOB predicts a generalization error of `r formatC(100*oob.accuracy, digits=3)`% which is
notably higher than our CV estimate and our measured hold-out error.

Other Caret Functions of Note
========================================================

&nbsp;

Recursive Feature Elimination

<center>**rfeIter** and **rfe**</center>

Questions?
========================================================

&nbsp;

https://github.com/Syrus/201311

<small>*This presentation was created with RStudio 0.98*</small>